import asyncio
import logging
import os
import random
import re
import threading

import colorlog
import httpx
import requests
import yaml
import google.generativeai as genai
import zhipuai
from mirai import Mirai, WebSocketAdapter, Voice, GroupMessage, At, Plain, Image
from mirai.bot import Startup
from openai import OpenAI
class CListen(threading.Thread):
    def __init__(self, loop):
        threading.Thread.__init__(self)
        self.mLoop = loop

    def run(self):
        asyncio.set_event_loop(self.mLoop)  # åœ¨æ–°çº¿ç¨‹ä¸­å¼€å¯ä¸€ä¸ªäº‹ä»¶å¾ªç¯

        self.mLoop.run_forever()
async def translate(text,mode="ZH_CN2JA"):
    URL=f"https://api.pearktrue.cn/api/translate/?text={text}&type={mode}"
    async with httpx.AsyncClient(timeout=20) as client:
        r = await client.get(URL)
        #print(r.json()["data"]["translate"])
        return r.json()["data"]["translate"]

def cozeBotRep(url,text,proxy,channelid=None):
    os.environ["http_proxy"] = proxy
    headers = {
        'accept': 'application/json',
        'Content-Type': 'application/json'
    }
    data = {
        "messages": text,
        "stream": False
    }

    r = requests.post(url, headers=headers, json=data)
    print(r)
    print(r.text)
    print(r)
    if r.status_code == 200:
        result = r.json()
        return result.get('choices')[0].get('message')

    else:
        print(f'Error: {r.status_code}')
def newLogger():
    # åˆ›å»ºä¸€ä¸ªloggerå¯¹è±¡
    logger = logging.getLogger("villia")
    # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºDEBUGï¼Œè¿™æ ·å¯ä»¥è¾“å‡ºæ‰€æœ‰çº§åˆ«çš„æ—¥å¿—
    logger.setLevel(logging.DEBUG)
    # åˆ›å»ºä¸€ä¸ªStreamHandlerå¯¹è±¡ï¼Œç”¨äºè¾“å‡ºæ—¥å¿—åˆ°æ§åˆ¶å°
    console_handler = logging.StreamHandler()
    # è®¾ç½®æ§åˆ¶å°è¾“å‡ºçš„æ—¥å¿—æ ¼å¼å’Œé¢œè‰²
    logger.propagate = False
    console_format = '%(log_color)s%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    console_colors = {
        'DEBUG': 'white',
        'INFO': 'cyan',
        'WARNING': 'yellow',
        'ERROR': 'red',
        'CRITICAL': 'bold_red',
    }
    console_formatter = colorlog.ColoredFormatter(console_format, log_colors=console_colors)
    console_handler.setFormatter(console_formatter)
    # å°†æ§åˆ¶å°å¤„ç†å™¨æ·»åŠ åˆ°loggerå¯¹è±¡ä¸­
    logger.addHandler(console_handler)
    # ä½¿ç”¨ä¸åŒçº§åˆ«çš„æ–¹æ³•æ¥è®°å½•ä¸åŒé‡è¦æ€§çš„äº‹ä»¶
    return logger
def random_str(random_length=6,chars='AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz0123456789@$#_%'):
    """
    ç”Ÿæˆéšæœºå­—ç¬¦ä¸²ä½œä¸ºéªŒè¯ç 
    :param random_length: å­—ç¬¦ä¸²é•¿åº¦,é»˜è®¤ä¸º6
    :return: éšæœºå­—ç¬¦ä¸²
    """
    string = ''

    length = len(chars) - 1
    # random = Random()
    # è®¾ç½®å¾ªç¯æ¯æ¬¡å–ä¸€ä¸ªå­—ç¬¦ç”¨æ¥ç”Ÿæˆéšæœºæ•°
    for i in range(7):
        string +=  ((chars[random.randint(0, length)]))
    return string
async def lolimigpt2(prompt,meta):
    url="https://api.lolimi.cn/API/AI/c.php?"
    prompt.insert(0,{"role":"user","content":meta})
    prompt.insert(1, {"role": "assistant", "content": "å¥½çš„ï¼Œå·²äº†è§£æ‚¨çš„éœ€æ±‚~æˆ‘ä¼šæ‰®æ¼”å¥½æ‚¨è®¾å®šçš„è§’è‰²"})
    async with httpx.AsyncClient(timeout=200) as client:
        r = await client.post(url=url,json=prompt)
        return {"role":"assistant","content":r.text}


async def geminirep(ak, messages):
    # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.
    GOOGLE_API_KEY = ak

    genai.configure(api_key=GOOGLE_API_KEY)

    # model = genai.GenerativeModel('gemini-pro')
    generation_config = {
        "candidate_count": 1,
        "max_output_tokens": 256,
        "temperature": 1.0,
        "top_p": 0.7,
    }

    safety_settings = [
        {
            "category": "HARM_CATEGORY_DANGEROUS",
            "threshold": "BLOCK_NONE",
        },
        {
            "category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_NONE",
        },
        {
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_NONE",
        },
        {
            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_NONE",
        },
        {
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_NONE",
        },
    ]

    model = genai.GenerativeModel(
        model_name="gemini-pro",
        generation_config=generation_config,
        safety_settings=safety_settings
    )

    # print(type(messages))

    response = model.generate_content(messages)

    # print(response.text)
    return response.text
async def glm4(prompt,meta):
    prompt.insert(0,{"role":"user","content":meta})
    prompt.insert(1, {"role": "assistant", "content": "å¥½çš„~"})
    url = f"https://api.lolimi.cn/API/AI/zp.php?msg={str(prompt)}"
    async with httpx.AsyncClient(timeout=100) as client:  # 100sè¶…æ—¶
        r = await client.get(url)  # å‘èµ·è¯·æ±‚
        #print(r.json())
        return {"role": "assistant", "content": r.json().get("data").get("output")}
def gptOfficial(prompt,apikeys,proxy,bot_info):
    os.environ["OPENAI_API_KEY"] = random.choice(apikeys)
    os.environ["http_proxy"] = proxy  # æŒ‡å®šä»£ç†ï¼Œè§£å†³è¿æ¥é—®é¢˜
    os.environ["https_proxy"] = proxy  # æŒ‡å®šä»£ç†ï¼Œè§£å†³è¿æ¥é—®é¢˜
    client = OpenAI(
        # This is the default and can be omitted
        api_key=os.environ.get("OPENAI_API_KEY"),
    )
    prompt.insert(0,{"role":"user","content":bot_info})
    chat_completion = client.chat.completions.create(
        messages=prompt,
        model="gpt-3.5-turbo",
        stream=False,
    )
    #print(chat_completion.choices[0].message.content)
    return {"role":"assistant","content":chat_completion.choices[0].message.content}
def gptUnofficial(prompt,apikeys,proxy,bot_info):
    os.environ["OPENAI_API_KEY"] = random.choice(apikeys)
    client = OpenAI(
        # This is the default and can be omitted
        base_url="https://api.chatanywhere.com.cn",
        api_key=os.environ.get("OPENAI_API_KEY"),
    )
    prompt.insert(0, {"role": "user", "content": bot_info})
    prompt.insert(1, {"role": "assistant", "content": "å¥½çš„ä¸»äººå–µ"})
    chat_completion = client.chat.completions.create(
        messages=prompt,
        model="gpt-3.5-turbo",
        stream=False,
    )
    # print(chat_completion.choices[0].message.content)
    return {"role": "assistant", "content": chat_completion.choices[0].message.content}

async def drawe(prompt,path= "./test.png"):
    url=f"https://api.lolimi.cn/API/AI/sd.php?msg={prompt}&mode=åŠ¨æ¼«"

    async with httpx.AsyncClient(timeout=40) as client:
        r = await client.get(url)
        with open(path,"wb") as f:
            f.write(r.content)
        # print(path)
        return path
async def draw1(prompt,path="./test.png"):
    url=f"https://api-collect.idcdun.com/v1/images/generations?prompt={prompt}&n=1&model=dall-e-3&size=1024x1024"
    async with httpx.AsyncClient(timeout=40) as client:
        r = await client.get(url)
        url2=r.json().get("data")[0].get("url")
        async with httpx.AsyncClient(timeout=40) as client:
            r1 = await client.get(url2)
        with open(path, "wb") as f:
            f.write(r1.content)
        # print(path)
        return path
def main(bot,logger):
    with open('data/noRes.yaml', 'r', encoding='utf-8') as f:
        noRes1 = yaml.load(f.read(), Loader=yaml.FullLoader)
    noRes=noRes1.get("noRes")
    with open('settings.yaml', 'r', encoding='utf-8') as f:
        result = yaml.load(f.read(), Loader=yaml.FullLoader)
    voicegg=result.get("chatGLM").get("voiceGenerateSource")
    glmReply = result.get("chatGLM").get("glmReply")
    replyModel = result.get("chatGLM").get("model")
    trustglmReply = result.get("chatGLM").get("trustglmReply")
    context= result.get("chatGLM").get("context")
    maxPrompt = result.get("chatGLM").get("maxPrompt")
    voiceLangType = str(result.get("chatGLM").get("langType"))
    allcharacters=result.get("chatGLM").get("bot_info")
    maxTextLen = result.get("chatGLM").get("maxLen")
    voiceRate = result.get("chatGLM").get("voiceRate")
    speaker = result.get("chatGLM").get("speaker")
    withText=result.get("chatGLM").get("withText")
    chatGLM_api_key=result.get("apiKeys").get("chatGLMKey")
    geminiapikey=result.get("apiKeys").get('geminiapiKey')
    gptkeys=result.get("apiKeys").get("openaikeys")
    proxy=result.get("proxy")
    CoziUrl=result.get("apiKeys").get("CoziUrl")
    botName=result.get("bot").get('botName')
    master=result.get("bot").get("master")
    gptdev=result.get("gpt3.5-dev")
    if proxy!="":
        os.environ["http_proxy"] = proxy
    newLoop = asyncio.new_event_loop()
    listen = CListen(newLoop)
    listen.setDaemon(True)
    listen.start()
    with open('data/chatGLMCharacters.yaml', 'r', encoding='utf-8') as f:
        result2223 = yaml.load(f.read(), Loader=yaml.FullLoader)
    global chatGLMCharacters
    chatGLMCharacters = result2223
    with open('data/GeminiData.yaml', 'r', encoding='utf-8') as f:
        cha0 = yaml.load(f.read(), Loader=yaml.FullLoader)
    global GeminiData
    GeminiData=cha0
    with open('data/chatGLMData.yaml', 'r', encoding='utf-8') as f:
        cha = yaml.load(f.read(), Loader=yaml.FullLoader)
    global chatGLMData
    chatGLMData=cha
    with open('data/permit.yaml', 'r', encoding='utf-8') as f:
        trusts = yaml.load(f.read(), Loader=yaml.FullLoader)
    global trustUser,trustGroups
    trustUser=trusts.get("users")
    trustGroups=trusts.get("groups")
    @bot.on(GroupMessage)
    async def aidrawf(event: GroupMessage):
        if str(event.message_chain).startswith("ç”» "):
            tag=str(event.message_chain).replace("ç”» ","")
            if os.path.exists("./data/pictures"):
                pass
            else:
                os.mkdir("./data/pictures")
            path = "data/pictures/" + random_str() + ".png"
            logger.info("å‘èµ·aiç»˜ç”»è¯·æ±‚ï¼Œpath:"+path+"|prompt:"+tag)
            try:
                logger.info("æ¥å£1ç»˜ç”»ä¸­......")
                p=await drawe(tag,path)
                await bot.send(event,Image(path=p),True)
            except Exception as e:
                logger.error(e)
                await bot.send(event,"æ¥å£ç»˜ç”»å¤±è´¥.......")
            try:
                logger.info("æ¥å£2ç»˜ç”»ä¸­......")
                p=await draw1(tag,path)
                await bot.send(event,Image(path=p),True)
            except Exception as e:
                logger.error(e)
                await bot.send(event,"æ¥å£2ç»˜ç”»å¤±è´¥.......")
    # ç”¨äºchatGLMæ¸…é™¤æœ¬åœ°ç¼“å­˜
    @bot.on(GroupMessage)
    async def clearPrompt(event: GroupMessage):
        global chatGLMData, GeminiData
        if str(event.message_chain) == "/clear":
            try:
                chatGLMData.pop(event.sender.id)
                # å†™å…¥æ–‡ä»¶
                with open('data/chatGLMData.yaml', 'w', encoding="utf-8") as file:
                    yaml.dump(chatGLMData, file, allow_unicode=True)
                await bot.send(event, "å·²æ¸…é™¤è¿‘æœŸè®°å¿†")
            except:
                logger.error("æ¸…ç†ç¼“å­˜å‡ºé”™ï¼Œæ— æœ¬åœ°å¯¹è¯è®°å½•")
            try:
                GeminiData.pop(event.sender.id)
                # å†™å…¥æ–‡ä»¶
                with open('data/GeminiData.yaml', 'w', encoding="utf-8") as file:
                    yaml.dump(GeminiData, file, allow_unicode=True)
                await bot.send(event, "å·²æ¸…é™¤è¿‘æœŸè®°å¿†")
            except:
                logger.error("æ¸…ç†ç¼“å­˜å‡ºé”™ï¼Œæ— æœ¬åœ°å¯¹è¯è®°å½•")
        elif str(event.message_chain) == "/allclear" and event.sender.id == master:
            try:
                chatGLMData = {"f": "hhh"}
                # chatGLMData.pop(event.sender.id)
                # å†™å…¥æ–‡ä»¶
                with open('data/chatGLMData.yaml', 'w', encoding="utf-8") as file:
                    yaml.dump(chatGLMData, file, allow_unicode=True)

                with open('data/GeminiData.yaml', 'w', encoding="utf-8") as file:
                    yaml.dump(chatGLMData, file, allow_unicode=True)
                await bot.send(event, "å·²æ¸…é™¤æ‰€æœ‰ç”¨æˆ·çš„prompt")
            except:
                await bot.send(event, "æ¸…ç†ç¼“å­˜å‡ºé”™ï¼Œæ— æœ¬åœ°å¯¹è¯è®°å½•")

    # ç¾¤å†…chatGLMå›å¤
    @bot.on(GroupMessage)
    async def atReply(event: GroupMessage):
        global chatGLMData, chatGLMCharacters,GeminiData,trustUser,trustGroups
        if At(bot.qq) in event.message_chain and (glmReply == True or (trustglmReply == True and str(event.sender.id) in trustUser) or event.group.id in trustGroups):
            if event.sender.id in chatGLMCharacters:
                if chatGLMCharacters.get(event.sender.id) == "gpt3.5":

                    rth = "gpt3.5"
                    await modelReply(event, rth)
                elif (chatGLMCharacters.get(event.sender.id) == "Cozi"):
                    await modelReply(event, chatGLMCharacters.get(event.sender.id))
                elif chatGLMCharacters.get(event.sender.id) == "lolimigpt":
                    await modelReply(event, chatGLMCharacters.get(event.sender.id))
                elif chatGLMCharacters.get(event.sender.id) == "glm-4":
                    await modelReply(event, chatGLMCharacters.get(event.sender.id))
                elif chatGLMCharacters.get(event.sender.id) == "Gemini":
                    text = str(event.message_chain).replace("@" + str(bot.qq) + "", '').replace(" ", "").replace("/g", "")
                    for saa in noRes:
                        if text == saa:
                            logger.warning("ä¸å±è”½è¯åŒ¹é…ï¼ŒGeminiä¸å›å¤")
                            return
                    logger.info("geminiå¼€å§‹è¿è¡Œ")
                    if text == "" or text == " ":
                        text = "åœ¨å—"
                    geminichar = allcharacters.get("Gemini").replace("ã€botã€‘", botName).replace("ã€ç”¨æˆ·ã€‘",
                                                                                               event.sender.member_name)
                    # æ„å»ºæ–°çš„prompt
                    tep = {"role": "user", "parts": [text]}
                    # print(type(tep))
                    # è·å–ä»¥å¾€çš„prompt
                    if event.sender.id in GeminiData and context == True:
                        prompt = GeminiData.get(event.sender.id)
                        prompt.append({"role": "user", 'parts': [text]})
                        # æ²¡æœ‰è¯¥ç”¨æˆ·ï¼Œä»¥æœ¬æ¬¡å¯¹è¯ä½œä¸ºprompt
                    else:
                        await bot.send(event, "å³å°†å¼€å§‹å¯¹è¯ï¼Œè¯·æ³¨æ„ï¼Œå¦‚æœé‡åˆ°å¯¹è¯å¼‚å¸¸ï¼Œè¯·å‘é€ /clear ä»¥æ¸…ç†å¯¹è¯è®°å½•(ä¸ç”¨è‰¾ç‰¹)", True)
                        prompt = [{"role": "user", "parts": [geminichar]},
                                  {"role": 'model', "parts": ["å¥½çš„ï¼Œå·²äº†è§£æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¼šæ‰®æ¼”å¥½ä½ è®¾å®šçš„è§’è‰²"]}]
                        prompt.append(tep)
                    logger.info("geminiæ¥æ”¶æé—®:" + text)
                    try:
                        # logger.info(geminiapikey)
                        r = await geminirep(ak=random.choice(geminiapikey), messages=prompt)
                        # æ›´æ–°è¯¥ç”¨æˆ·prompt
                        prompt.append({"role": 'model', "parts": [r]})
                        await tstt(r, event)

                        GeminiData[event.sender.id] = prompt
                        # å†™å…¥æ–‡ä»¶
                        with open('data/GeminiData.yaml', 'w', encoding="utf-8") as file:
                            yaml.dump(GeminiData, file, allow_unicode=True)

                        # asyncio.run_coroutine_threadsafe(asyncgemini(geminiapikey,prompt, event,text), newLoop)
                        # st1 = await chatGLM(selfApiKey, meta1, prompt)
                    except Exception as e:
                        logger.error(e)
                        await bot.send(event, "geminiå¯åŠ¨å‡ºé”™\nè¯·é‡è¯•")
                elif type(chatGLMCharacters.get(event.sender.id)) == dict:
                    text = str(event.message_chain).replace("@" + str(bot.qq) + "", '').replace(" ", "")
                    logger.info("åˆ†æ”¯1")
                    for saa in noRes:
                        if text == saa:
                            logger.warning("ä¸å±è”½è¯åŒ¹é…ï¼ŒchatGLMä¸å›å¤")
                            return
                    if text == "" or text == " ":
                        text = "åœ¨å—"
                    # æ„å»ºæ–°çš„prompt
                    tep = {"role": "user", "content": text}
                    # print(type(tep))
                    # è·å–ä»¥å¾€çš„prompt
                    if event.sender.id in chatGLMData and context == True:
                        prompt = chatGLMData.get(event.sender.id)
                        prompt.append({"role": "user", "content": text})

                    # æ²¡æœ‰è¯¥ç”¨æˆ·ï¼Œä»¥æœ¬æ¬¡å¯¹è¯ä½œä¸ºprompt
                    else:
                        await bot.send(event, "å³å°†å¼€å§‹å¯¹è¯ï¼Œè¯·æ³¨æ„ï¼Œå¦‚æœé‡åˆ°å¯¹è¯å¼‚å¸¸ï¼Œè¯·å‘é€ /clear ä»¥æ¸…ç†å¯¹è¯è®°å½•(ä¸ç”¨è‰¾ç‰¹)", True)
                        prompt = [tep]
                        chatGLMData[event.sender.id] = prompt
                    # æˆ–è€…å¼€å¯äº†ä¿¡ä»»ç”¨æˆ·å›å¤ä¸”ä¸ºä¿¡ä»»ç”¨æˆ·
                    if str(event.sender.id) in trustUser and trustglmReply == True:
                        logger.info("ä¿¡ä»»ç”¨æˆ·è¿›è¡ŒchatGLMæé—®")
                        selfApiKey = chatGLM_api_key
                    elif glmReply == True:
                        logger.info("å¼€æ”¾ç¾¤èŠglmæé—®")
                        selfApiKey = chatGLM_api_key
                    else:
                        await bot.send(event, "Error,è¯¥æ¨¡å‹ä¸å¯ç”¨")
                        return

                    # è·å–è§’è‰²è®¾å®š
                    if event.sender.id in chatGLMCharacters:
                        meta1 = chatGLMCharacters.get(event.sender.id)
                    else:
                        logger.warning("è¯»å–metaæ¨¡æ¿")
                        with open('settings.yaml', 'r', encoding='utf-8') as f:
                            resy = yaml.load(f.read(), Loader=yaml.FullLoader)
                        meta1 = resy.get("chatGLM").get("bot_info").get("default")


                    setName = event.sender.member_name
                    meta1["user_name"] = meta1.get("user_name").replace("æŒ‡æŒ¥", setName)
                    meta1["user_info"] = meta1.get("user_info").replace("æŒ‡æŒ¥", setName).replace("yucca", botName)
                    meta1["bot_info"] = meta1.get("bot_info").replace("æŒ‡æŒ¥", setName).replace("yucca", botName)
                    meta1["bot_name"] = botName

                    logger.info("chatGLMæ¥æ”¶æé—®:" + text)
                    try:
                        logger.info("å½“å‰meta:" + str(meta1))
                        asyncio.run_coroutine_threadsafe(asyncchatGLM(selfApiKey, meta1, prompt, event, setName, text),
                                                         newLoop)
                        # st1 = await chatGLM(selfApiKey, meta1, prompt)


                    except:
                        await bot.send(event, "chatGLMå¯åŠ¨å‡ºé”™ï¼Œè¯·è”ç³»master\næˆ–é‡è¯•")
            # åˆ¤æ–­æ¨¡å‹
            elif replyModel == "gpt3.5":

                rth = "gpt3.5"
                await modelReply(event, rth)
            elif replyModel == "Cozi":
                await modelReply(event, replyModel)
            elif replyModel == "glm-4":
                await modelReply(event, replyModel)
            elif replyModel == "lolimigpt" :
                await modelReply(event, replyModel)
            elif replyModel == "Gemini" :
                text = str(event.message_chain).replace("@" + str(bot.qq) + "", '').replace(" ", "").replace("/g", "")
                for saa in noRes:
                    if text == saa:
                        logger.warning("ä¸å±è”½è¯åŒ¹é…ï¼ŒGeminiä¸å›å¤")
                        return
                logger.info("geminiå¼€å§‹è¿è¡Œ")
                if text == "" or text == " ":
                    text = "åœ¨å—"
                # æ„å»ºæ–°çš„prompt
                tep = {"role": "user", "parts": [text]}
                geminichar = allcharacters.get("Gemini").replace("ã€botã€‘", botName).replace("ã€ç”¨æˆ·ã€‘",
                                                                                           event.sender.member_name)
                # print(type(tep))
                # è·å–ä»¥å¾€çš„prompt
                if event.sender.id in GeminiData and context == True:
                    prompt = GeminiData.get(event.sender.id)
                    prompt.append({"role": "user", 'parts': [text]})
                    # æ²¡æœ‰è¯¥ç”¨æˆ·ï¼Œä»¥æœ¬æ¬¡å¯¹è¯ä½œä¸ºprompt
                else:
                    await bot.send(event, "å³å°†å¼€å§‹å¯¹è¯ï¼Œè¯·æ³¨æ„ï¼Œå¦‚æœé‡åˆ°å¯¹è¯å¼‚å¸¸ï¼Œè¯·å‘é€ /clear ä»¥æ¸…ç†å¯¹è¯è®°å½•(ä¸ç”¨è‰¾ç‰¹)", True)
                    prompt = [{"role": "user", "parts": [geminichar]},
                              {"role": 'model', "parts": ["å¥½çš„ï¼Œå·²äº†è§£æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¼šæ‰®æ¼”å¥½ä½ è®¾å®šçš„è§’è‰²"]}]
                    prompt.append(tep)
                logger.info("geminiæ¥æ”¶æé—®:" + text)
                try:
                    # logger.info(geminiapikey)
                    r = await geminirep(ak=random.choice(geminiapikey), messages=prompt)
                    # æ›´æ–°è¯¥ç”¨æˆ·prompt
                    prompt.append({"role": 'model', "parts": [r]})
                    await tstt(r, event)

                    GeminiData[event.sender.id] = prompt
                    # å†™å…¥æ–‡ä»¶
                    with open('data/GeminiData.yaml', 'w', encoding="utf-8") as file:
                        yaml.dump(GeminiData, file, allow_unicode=True)

                    # asyncio.run_coroutine_threadsafe(asyncgemini(geminiapikey,prompt, event,text), newLoop)
                    # st1 = await chatGLM(selfApiKey, meta1, prompt)
                except Exception as e:
                    logger.error(e)
                    GeminiData.pop(event.sender.id)
                    # å†™å…¥æ–‡ä»¶
                    with open('data/GeminiData.yaml', 'w', encoding="utf-8") as file:
                        yaml.dump(GeminiData, file, allow_unicode=True)
                    await bot.send(event, "geminiå¯åŠ¨å‡ºé”™\nè¯·é‡è¯•")
            elif replyModel == "characterglm":
                text = str(event.message_chain).replace("@" + str(bot.qq) + "", '').replace(" ", "")
                logger.info("åˆ†æ”¯1")
                for saa in noRes:
                    if text == saa:
                        logger.warning("ä¸å±è”½è¯åŒ¹é…ï¼ŒchatGLMä¸å›å¤")
                        return
                if text == "" or text == " ":
                    text = "åœ¨å—"
                # æ„å»ºæ–°çš„prompt
                tep = {"role": "user", "content": text}
                # print(type(tep))
                # è·å–ä»¥å¾€çš„prompt
                if event.sender.id in chatGLMData and context == True:
                    prompt = chatGLMData.get(event.sender.id)
                    prompt.append({"role": "user", "content": text})

                # æ²¡æœ‰è¯¥ç”¨æˆ·ï¼Œä»¥æœ¬æ¬¡å¯¹è¯ä½œä¸ºprompt
                else:
                    await bot.send(event, "å³å°†å¼€å§‹å¯¹è¯ï¼Œè¯·æ³¨æ„ï¼Œå¦‚æœé‡åˆ°å¯¹è¯å¼‚å¸¸ï¼Œè¯·å‘é€ /clear ä»¥æ¸…ç†å¯¹è¯è®°å½•(ä¸ç”¨è‰¾ç‰¹)", True)
                    prompt = [tep]
                    chatGLMData[event.sender.id] = prompt
                # logger.info("å½“å‰prompt"+str(prompt))
                selfApiKey = chatGLM_api_key
                # è·å–è§’è‰²è®¾å®š
                if event.sender.id in chatGLMCharacters:
                    meta1 = chatGLMCharacters.get(event.sender.id)
                else:
                    logger.warning("è¯»å–metaæ¨¡æ¿")
                    with open('settings.yaml', 'r', encoding='utf-8') as f:
                        resy = yaml.load(f.read(), Loader=yaml.FullLoader)
                    meta1 = resy.get("chatGLM").get("bot_info").get("default")

                setName = event.sender.member_name
                meta1["user_name"] = meta1.get("user_name").replace("æŒ‡æŒ¥", setName)
                meta1["user_info"] = meta1.get("user_info").replace("æŒ‡æŒ¥", setName).replace("yucca", botName)
                meta1["bot_info"] = meta1.get("bot_info").replace("æŒ‡æŒ¥", setName).replace("yucca", botName)
                meta1["bot_name"] = botName

                logger.info("chatGLMæ¥æ”¶æé—®:" + text)
                try:
                    logger.info("å½“å‰meta:" + str(meta1))
                    asyncio.run_coroutine_threadsafe(asyncchatGLM(selfApiKey, meta1, prompt, event, setName, text), newLoop)
                    # st1 = await chatGLM(selfApiKey, meta1, prompt)


                except:
                    await bot.send(event, "chatGLMå¯åŠ¨å‡ºé”™ï¼Œè¯·è”ç³»master\næˆ–é‡è¯•")

    @bot.on(GroupMessage)
    async def permitUserandGroup(event:GroupMessage):
        global trustUser, trustGroups
        if event.sender.id==master:
            if str(event.message_chain).startswith("æˆæƒ#"):
                try:
                    trustUser.append(int(str(event.message_chain).replace("æˆæƒ#","")))
                    ppp={"groups":trustGroups,"users":trustUser}
                    with open('data/permit.yaml', 'w', encoding="utf-8") as file:
                        yaml.dump(ppp, file, allow_unicode=True)
                    await bot.send(event,"æˆæƒæˆåŠŸ")
                except:
                    await bot.send(event,"æˆæƒå¤±è´¥")
            elif str(event.message_chain).startswith("æˆæƒç¾¤#"):
                try:
                    trustGroups.append(int(str(event.message_chain).replace("æˆæƒç¾¤#","")))
                    ppp={"groups":trustGroups,"users":trustUser}
                    with open('data/permit.yaml', 'w', encoding="utf-8") as file:
                        yaml.dump(ppp, file, allow_unicode=True)
                    await bot.send(event,"æˆæƒç¾¤æˆåŠŸ")
                except:
                    await bot.send(event,"æˆæƒå¤±è´¥")
    @bot.on(Startup)
    async def sgggggg(event: Startup):
        await bot.send_friend_message(master,"masteræŒ‡ä»¤ï¼š\næˆæƒç¾¤#ç¾¤å·\næˆæƒ#QQå·\n\nç”¨æˆ·æŒ‡ä»¤ï¼š\n@bot è§’è‰²")
    @bot.on(GroupMessage)
    async def ttsssss(event: GroupMessage):
        modelScope = ["BT", "å¡”è²", "é˜¿æ¢“", "otto", "ä¸çœŸ", "æ˜Ÿç³", "ä¸œé›ªè²", "å˜‰ç„¶", "å­™ç¬‘å·", "äºšæ‰˜å…‹æ–¯", "æ–‡é™", "é¹¿é¸£", "å¥¶ç»¿", "ä¸ƒæµ·", "æ¬è±†",
                      "ç§‘æ¯”"]
        outVitsSpeakers = "ç©º, è§, æ´¾è’™, çº³è¥¿å¦², é˜¿è´å¤š, æ¸©è¿ª, æ«åŸä¸‡å¶, é’Ÿç¦», è’æ³·ä¸€æ–—, å…«é‡ç¥å­, è‰¾å°”æµ·æ£®, æçº³é‡Œ, è¿ªå¸Œé›…, å¡ç»´, å®µå®«, è±ä¾æ‹‰, èµ›è¯º, è¯ºè‰¾å°”, æ‰˜é©¬, å‡å…‰, è«å¨œ, åŒ—æ–—, ç¥é‡Œç»«å, é›·ç”µå°†å†›, èŠ­èŠ­æ‹‰, é¹¿é‡é™¢å¹³è—, äº”éƒ, è¿ªå¥¥å¨œ, å‡¯äºš, å®‰æŸ, ç­å°¼ç‰¹, ç´, æŸ¯è±, å¤œå…°, å¦®éœ², è¾›ç„±, çéœ²çŠ, é­ˆ, é¦™è±, è¾¾è¾¾åˆ©äºš, ç ‚ç³–, æ—©æŸš, äº‘å ‡, åˆ»æ™´, ä¸½è, è¿ªå¢å…‹, çƒŸç»¯, é‡äº‘, çŠç‘šå®«å¿ƒæµ·, èƒ¡æ¡ƒ, å¯è‰, æµæµªè€…, ä¹…å²å¿, ç¥é‡Œç»«äºº, ç”˜é›¨, æˆ´å› æ–¯é›·å¸ƒ, ä¼˜èˆ, è²è°¢å°”, è¡Œç§‹, ç™½æœ¯, ä¹æ¡è£Ÿç½—, é›·æ³½, ç”³é¹¤, è¿ªå¨œæ³½é»›, å‡¯ç‘Ÿç³, å¤šè‰, åè’‚ä¸, èå§¥å§¥, ç½—èè‰äºš, ç•™äº‘å€Ÿé£çœŸå›, ç»®è‰¯è‰¯, ç‘¶ç‘¶, ä¸ƒä¸ƒ, å¥¥å…¹, ç±³å¡, å¤æ´›è’‚, åŸƒæ´›ä¼Š, åšå£«, å¥³å£«, å¤§æ…ˆæ ‘ç‹, ä¸‰æœˆä¸ƒ, å¨œå¡”è, å¸Œéœ²ç“¦, è™å…‹, å…‹æ‹‰æ‹‰, ä¸¹æ’, å¸Œå„¿, å¸ƒæ´›å¦®å¨…, ç“¦å°”ç‰¹, æ°å¸•å¾·, ä½©æ‹‰, å§¬å­, è‰¾ä¸å¦², ç™½éœ², æ˜Ÿ, ç©¹, æ¡‘åš, ä¼¦çº³å¾·, åœäº‘, ç½—åˆ¹, å¡èŠ™å¡, å½¦å¿, å²ç“¦ç½—, èºä¸å’•å§†, é˜¿å…°, é“¶ç‹¼, ç´ è£³, ä¸¹æ¢, é»‘å¡”, æ™¯å…ƒ, å¸•å§†, å¯å¯åˆ©äºš, åŠå¤, ç¬¦ç„, å…¬è¾“å¸ˆå‚…, å¥¥åˆ—æ ¼, é’é›€, å¤§æ¯«, é’é•, è´¹æ–¯æ›¼, ç»¿èŠ™è“‰, é•œæµ, ä¿¡ä½¿, ä¸½å¡”, å¤±è½è¿·è¿­, ç¼­ä¹±æ˜Ÿæ£˜, ä¼Šç”¸, ä¼ç‰¹åŠ å¥³å­©, ç‹‚çƒ­è“è°ƒ, è‰è‰å¨…, èèè‰å¨…, å…«é‡æ¨±, å…«é‡éœ, å¡è², ç¬¬å…­å¤œæƒ³æ›², å¡èå°”, å§¬å­, æåœ°æˆ˜åˆƒ, å¸ƒæ´›å¦®å¨…, æ¬¡ç”Ÿé“¶ç¿¼, ç†ä¹‹å¾‹è€…, çœŸç†ä¹‹å¾‹è€…, è¿·åŸéª‡å…”, å¸Œå„¿, é­‡å¤œæ˜Ÿæ¸Š, é»‘å¸Œå„¿, å¸•æœµè²è‰ä¸, å¤©å…ƒéª‘è‹±, å¹½å…°é»›å°”, å¾·ä¸½è, æœˆä¸‹åˆæ‹¥, æœ”å¤œè§‚æ˜Ÿ, æš®å…‰éª‘å£«, æ˜æ—¥é¦™, æç´ è£³, æ ¼è•¾ä¿®, æ¢…æ¯”ä¹Œæ–¯, æ¸¡é¸¦, äººä¹‹å¾‹è€…, çˆ±è‰å¸Œé›…, çˆ±è¡£, å¤©ç©¹æ¸¸ä¾ , çªäºšå¨œ, ç©ºä¹‹å¾‹è€…, ç»ˆç„‰ä¹‹å¾‹è€…, è–ªç‚ä¹‹å¾‹è€…, äº‘å¢¨ä¸¹å¿ƒ, ç¬¦å, è¯†ä¹‹å¾‹è€…, ç»´å°”è–‡, å§‹æºä¹‹å¾‹è€…, èŠ½è¡£, é›·ä¹‹å¾‹è€…, è‹èå¨œ, é˜¿æ³¢å°¼äºš, é™†æ™¯å’Œ, è«å¼ˆ, å¤å½¦, å·¦ç„¶".replace(
            " ", "").split(",")
        msg = "".join(map(str, event.message_chain[Plain]))
        # åŒ¹é…æŒ‡ä»¤
        if "è¯´" in str(event.message_chain):
            if str(event.message_chain).split("è¯´")[0] in modelScope:
                spk=str(event.message_chain).split("è¯´")[0]
                txt=str(event.message_chain).replace(spk+"è¯´","")
                logger.info(f"è¯­éŸ³åˆæˆä»»åŠ¡ text: {txt}, speaker: {spk}")
                p=await superVG({"text": txt, "speaker": spk},"modelscopeTTS")
                await bot.send(event,Voice(path=p))
            if str(event.message_chain).split("è¯´")[0] in outVitsSpeakers:
                spk = str(event.message_chain).split("è¯´")[0]
                txt = str(event.message_chain).replace(spk + "è¯´", "")
                logger.info(f"è¯­éŸ³åˆæˆä»»åŠ¡ text: {txt}, speaker: {spk}")
                p=await superVG({"text": txt, "speaker": spk}, "outVits")
                await bot.send(event, Voice(path=p))
        if "è§’è‰²" in str(event.message_chain) and At(bot.qq) in event.message_chain:
            str1=""
            str1 += "outVitsè¯­éŸ³åˆæˆå¯ç”¨è§’è‰²å¦‚ä¸‹ï¼š\n" + str(outVitsSpeakers) + "\n\nbert_vits2å¯ç”¨è§’è‰²å¦‚ä¸‹ï¼š\n" + str(
                ["BT", "å¡”è²", "é˜¿æ¢“", "otto", "ä¸çœŸ", "æ˜Ÿç³", "ä¸œé›ªè²", "å˜‰ç„¶", "å­™ç¬‘å·", "äºšæ‰˜å…‹æ–¯", "æ–‡é™", "é¹¿é¸£", "å¥¶ç»¿", "ä¸ƒæµ·", "æ¬è±†", "ç§‘æ¯”"])
            await bot.send(event, str1)
            await bot.send(event, "å¯å‘é€ xxè¯´.......  ä»¥è¿›è¡Œè¯­éŸ³åˆæˆ")
    async def tstt(r, event):
        if len(r) < maxTextLen and random.randint(0, 100) < voiceRate and event.type != 'FriendMessage':
            data1 = {}
            data1['speaker'] = speaker

            # print(path)
            st8 = re.sub(r"ï¼ˆ[^ï¼‰]*ï¼‰", "", r)  # ä½¿ç”¨rå‰ç¼€è¡¨ç¤ºåŸå§‹å­—ç¬¦ä¸²ï¼Œé¿å…è½¬ä¹‰å­—ç¬¦çš„é—®é¢˜
            data1["text"] = st8
            st1 = r
            try:

                logger.info(f"è°ƒç”¨{voicegg}è¯­éŸ³åˆæˆ")
                path = await superVG(data1, voicegg, voiceLangType)
                await bot.send(event, Voice(path=path))
                if withText == True:
                    await bot.send(event, st1, True)
            except Exception as e:
                logger.error(e)
                await bot.send(event, st1, True)

        else:
            await bot.send(event, r, True)
    async def modelReply(event,modelHere):
        global chatGLMData, chatGLMCharacters,GeminiData

        if event.type != 'FriendMessage':
            bot_in = str(f"ä½ æ˜¯{botName},æˆ‘æ˜¯" + event.sender.member_name + "," + allcharacters.get(
            "gpt3.5")).replace("ã€botã€‘",botName).replace("ã€ç”¨æˆ·ã€‘", event.sender.member_name)
            lolimi_bot_in = str("ä½ æ˜¯" + botName + ",æˆ‘æ˜¯" + event.sender.member_name + "," + allcharacters.get(
                "lolimigpt")).replace("ã€botã€‘",botName).replace("ã€ç”¨æˆ·ã€‘", event.sender.member_name)
            glm4_bot_in = str("ä½ æ˜¯" + botName + ",æˆ‘æ˜¯" + event.sender.member_name + "," + allcharacters.get(
                "glm-4")).replace("ã€botã€‘",botName).replace("ã€ç”¨æˆ·ã€‘", event.sender.member_name)
        else:
            bot_in = str("ä½ æ˜¯" + botName + ",æˆ‘æ˜¯" + event.sender.nickname + "," + allcharacters.get(
                "gpt3.5")).replace("ã€botã€‘",
                                   botName).replace("ã€ç”¨æˆ·ã€‘", event.sender.nickname)
            lolimi_bot_in = str("ä½ æ˜¯" + botName + ",æˆ‘æ˜¯" + event.sender.nickname + "," + allcharacters.get(
                "lolimigpt")).replace("ã€botã€‘",
                                      botName).replace("ã€ç”¨æˆ·ã€‘", event.sender.nickname)
            glm4_bot_in = str("ä½ æ˜¯" + botName + ",æˆ‘æ˜¯" + event.sender.nickname + "," + allcharacters.get(
                "glm-4")).replace("ã€botã€‘",
                                      botName).replace("ã€ç”¨æˆ·ã€‘", event.sender.nickname)
        try:
            text = str(event.message_chain).replace("@" + str(bot.qq) + " ", '').replace("/gpt", "")
            if text == "" or text == " ":
                text = "åœ¨å—"
            for saa in noRes:
                #print(text, saa)
                if text == saa:

                    logger.warning("ä¸å±è”½è¯åŒ¹é…ï¼Œä¸å›å¤")
                    return
            if event.sender.id in chatGLMData:
                prompt1 = chatGLMData.get(event.sender.id)
                prompt1.append({"content": text, "role": "user"})
            else:
                prompt1 = [{"content": text, "role": "user"}]
                await bot.send(event, "å³å°†å¼€å§‹å¯¹è¯ï¼Œå¦‚æœé‡åˆ°å¼‚å¸¸è¯·å‘é€ /clear æ¸…ç†å¯¹è¯")
            logger.info(f"{modelHere}  bot æ¥å—æé—®ï¼š" + text)
            loop = asyncio.get_event_loop()
            if modelHere=="gpt3.5":
                if gptdev==False:
                    rep = await loop.run_in_executor(None, gptOfficial, prompt1, gptkeys, proxy, bot_in)
                else:
                    rep = await loop.run_in_executor(None, gptUnofficial, prompt1, gptkeys, proxy, bot_in)
            elif modelHere=="Cozi":
                rep = await loop.run_in_executor(None, cozeBotRep, CoziUrl, prompt1, proxy)
            elif modelHere=="lolimigpt":
                rep = await lolimigpt2(prompt1,lolimi_bot_in)
                if "ä»¤ç‰Œé¢åº¦" in rep.get("content"):
                    logger.error("æ²¡é‡‘å¸äº†å–µ")
                    await bot.send(event, "apiæ²¡é‡‘å¸äº†å–µ\nè¯·å‘é€ @bot å¯ç”¨è§’è‰²æ¨¡æ¿ ä»¥æ›´æ¢å…¶ä»–æ¨¡å‹", True)
                    return
                if "æ•æ„Ÿè¯æ±‡" in rep.get("content"):
                    logger.error("æ•æ„Ÿè¯äº†æè¿™")
                    await bot.send(event, "è§¦å‘äº†æ•æ„Ÿè¯å®¡æ ¸ï¼Œå·²è‡ªåŠ¨æ¸…ç†èŠå¤©è®°å½•", True)
                    try:
                        chatGLMData.pop(event.sender.id)
                    except Exception as e:
                        logger.error(e)
                    return

            elif modelHere=="glm-4":
                rep=await glm4(prompt1,glm4_bot_in)
                if "ç¦æ­¢è¿è§„é—®ç­”" == rep.get("content"):
                    logger.error("æ•æ„Ÿå–½ï¼Œä¸èƒ½ç”¨äº†")
                    await bot.send(event,rep.get("content"))
                    await bot.send(event,"è§¦å‘äº†æ•æ„Ÿå†…å®¹å®¡æ ¸ï¼Œå·²è‡ªåŠ¨æ¸…ç†èŠå¤©è®°å½•")
                    try:
                        chatGLMData.pop(event.sender.id)
                    except Exception as e:
                        logger.error(e)
                    return
            prompt1.append(rep)
            # è¶…è¿‡10ï¼Œç§»é™¤ç¬¬ä¸€ä¸ªå…ƒç´ 

            if len(prompt1) > maxPrompt:
                logger.error(f"{modelHere} promptè¶…é™ï¼Œç§»é™¤å…ƒç´ ")
                del prompt1[0]
                del prompt1[0]
            chatGLMData[event.sender.id] = prompt1
            # å†™å…¥æ–‡ä»¶
            with open('data/chatGLMData.yaml', 'w', encoding="utf-8") as file:
                yaml.dump(chatGLMData, file, allow_unicode=True)
            logger.info(f"{modelHere} bot å›å¤ï¼š" + rep.get('content'))
            await tstt(rep.get('content'), event)
        except Exception as e:
            logger.error(e)
            try:
                chatGLMData.pop(event.sender.id)
                logger.info("æ¸…ç†ç”¨æˆ·prompt")
            except Exception as e:
                logger.error("æ¸…ç†ç”¨æˆ·promptå‡ºé”™")

            await bot.send(event, "å‡ºé”™ï¼Œè‡ªåŠ¨æ¸…ç†å¼‚å¸¸prompt.....è¯·é‡è¯•ï¼Œå¦‚æœæ— æ•ˆè¯· è”ç³»masteråé¦ˆé—®é¢˜", True)

    async def superVG(data, mode, langmode="<zh>"):
        if langmode == "<jp>":
            try:
                # r=await translate(data.get("text"))
                # print(r)
                data["text"] = await translate(data.get("text"))
            except:
                print("è¯­éŸ³åˆæˆç¿»è¯‘å‡ºé”™")
        elif langmode == "<en>":
            try:
                # r=await translate(data.get("text"))
                # print(r)
                data["text"] = await translate(data.get("text"), "ZH_CN2EN")
            except:
                print("è¯­éŸ³åˆæˆç¿»è¯‘å‡ºé”™")
        if mode == "outVits":
            speaker = data.get("speaker")
            text = data.get("text")
            # os.system("where python")
            # p = random_str() + ".mp3"
            # p = "data/voices/" + p
            p = "data/voices/" + random_str() + '.wav'
            url = f"https://api.lolimi.cn/API/yyhc/y.php?msg={text}&speaker={speaker}"
            async with httpx.AsyncClient(timeout=200) as client:
                r = await client.post(url)
                newUrl = r.json().get("music")
                print("outvitsè¯­éŸ³åˆæˆè·¯å¾„ï¼š" + p)
                r1 = requests.get(newUrl)
                with open(p, "wb") as f:
                    f.write(r1.content)
                # await change_sample_rate(p)
                return p
        elif mode == "modelscopeTTS":
            speaker = data.get("speaker")
            text = data.get("text")
            if text == "" or text == " ":
                text = "å“¼å“¼"
            if speaker == "é˜¿æ¢“":
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Azusa-Bert-VITS2-2.3/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Azusa-Bert-VITS2-2.3/gradio/file="
            elif speaker == "otto":
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/otto-Bert-VITS2-2.3/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/otto-Bert-VITS2-2.3/gradio/file="
            elif speaker == "å¡”è²":
                speaker = "taffy"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Taffy-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Taffy-Bert-VITS2/gradio/file="
            elif speaker == "æ˜Ÿç³":
                speaker = "XingTong"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/XingTong-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/XingTong-Bert-VITS2/gradio/file="
            elif speaker == "ä¸çœŸ":
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/DZ-Bert-VITS2-2.3/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/DZ-Bert-VITS2-2.3/gradio/file="
            elif speaker == "ä¸œé›ªè²":
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Azuma-Bert-VITS2-2.3/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Azuma-Bert-VITS2-2.3/gradio/file="
            elif speaker == "å˜‰ç„¶":
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Diana-Bert-VITS2-2.3/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Diana-Bert-VITS2-2.3/gradio/file="
            elif speaker == "å­™ç¬‘å·":
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/SXC-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/SXC-Bert-VITS2/gradio/file="
            elif speaker == "é¹¿é¸£":
                speaker = "Lumi"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Lumi-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Lumi-Bert-VITS2/gradio/file="
            elif speaker == "æ–‡é™":
                speaker = "Wenjing"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Wenjing-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Wenjing-Bert-VITS2/gradio/file="
            elif speaker == "äºšæ‰˜å…‹æ–¯":
                speaker = "Aatrox"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Aatrox-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Aatrox-Bert-VITS2/gradio/file="
            elif speaker == "å¥¶ç»¿":
                speaker = "æ˜å‰å¥¶ç»¿"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/LAPLACE-Bert-VITS2-2.3/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/LAPLACE-Bert-VITS2-2.3/gradio/file="
            elif speaker == "ä¸ƒæµ·":
                speaker = "Nana7mi"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Nana7mi-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Nana7mi-Bert-VITS2/gradio/file="
            elif speaker == "æ¬è±†":
                speaker = "Bekki"
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Bekki-Bert-VITS2/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Bekki-Bert-VITS2/gradio/file="
            elif speaker == "ç§‘æ¯”":
                url = "https://www.modelscope.cn/api/v1/studio/xzjosh/Kobe-Bert-VITS2-2.3/gradio/run/predict"
                newurp = "https://www.modelscope.cn/api/v1/studio/xzjosh/Kobe-Bert-VITS2-2.3/gradio/file="
            data = {
                "data": [text, speaker, 0.5, 0.5, 0.9, 1, "auto", None, "Happy", "Text prompt", "", 0.7],
                "event_data": None,
                "fn_index": 0,
                "dataType": ["textbox", "dropdown", "slider", "slider", "slider", "slider", "dropdown", "audio",
                             "textbox",
                             "radio", "textbox", "slider"],
                "session_hash": "xjwen214wqf"
            }
            p = "data/voices/" + random_str() + '.wav'
            async with httpx.AsyncClient(timeout=200) as client:
                r = await client.post(url, json=data)
                newurl = newurp + \
                         r.json().get("data")[1].get("name")
                async with httpx.AsyncClient(timeout=200) as client:
                    r = await client.get(newurl)
                    with open(p, "wb") as f:
                        f.write(r.content)
                    return p

    # CharacterchatGLMéƒ¨åˆ†
    def chatGLM(api_key, bot_info, prompt, model1):
        model1 = "characterglm"
        logger.info("å½“å‰æ¨¡å¼:" + model1)
        zhipuai.api_key = api_key
        if model1 == "chatglm_pro":
            response = zhipuai.model_api.sse_invoke(
                model="chatglm_pro",
                prompt=prompt,
                temperature=0.95,
                top_p=0.7,
                incremental=True
            )
        elif model1 == "chatglm_std":
            response = zhipuai.model_api.sse_invoke(
                model="chatglm_std",
                prompt=prompt,
                temperature=0.95,
                top_p=0.7,
                incremental=True
            )
        elif model1 == "chatglm_lite":
            response = zhipuai.model_api.sse_invoke(
                model="chatglm_lite",
                prompt=prompt,
                temperature=0.95,
                top_p=0.7,
            )
        else:
            response = zhipuai.model_api.sse_invoke(
                model="characterglm",
                meta=bot_info,
                prompt=prompt,
                incremental=True
            )
        str1 = ""
        for event in response.events():
            if event.event == "add":
                str1 += event.data
                # print(event.data)
            elif event.event == "error" or event.event == "interrupted":
                str1 += event.data
                # print(event.data)
            elif event.event == "finish":
                str1 += event.data
                # print(event.data)
                print(event.meta)
            else:
                str1 += event.data
                # print(event.data)
        # print(str1)
        return str1

    # åˆ›å»ºä¸€ä¸ªå¼‚æ­¥å‡½æ•°
    async def asyncchatGLM(apiKey, bot_info, prompt, event, setName, text):
        global chatGLMData

        loop = asyncio.get_event_loop()
        # ä½¿ç”¨ loop.run_in_executor() æ–¹æ³•æ¥å°†åŒæ­¥å‡½æ•°è½¬æ¢ä¸ºå¼‚æ­¥éé˜»å¡çš„æ–¹å¼è¿›è¡Œå¤„ç†
        # ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ‰§è¡Œå™¨ï¼Œå¯ä»¥æ˜¯ Noneã€ThreadPoolExecutor æˆ– ProcessPoolExecutor
        # ç¬¬äºŒä¸ªå‚æ•°æ˜¯åŒæ­¥å‡½æ•°åï¼Œåé¢è·Ÿç€ä»»ä½•ä½ éœ€è¦ä¼ é€’çš„å‚æ•°
        # result=chatGLM(apiKey,bot_info,prompt)
        with open('settings.yaml', 'r', encoding='utf-8') as f:
            result = yaml.load(f.read(), Loader=yaml.FullLoader)
        model1 = result.get("chatGLM").get("model")
        st1 = await loop.run_in_executor(None, chatGLM, apiKey, bot_info, prompt, model1)
        # æ‰“å°ç»“æœ
        # print(result)
        st11 = st1.replace(setName, "æŒ‡æŒ¥")
        logger.info("chatGLM:" + st1)
        if len(st1) < maxTextLen and random.randint(0, 100) < voiceRate and event.type != 'FriendMessage':
            data1 = {}
            data1['speaker'] = speaker

            # print(path)
            st8 = re.sub(r"ï¼ˆ[^ï¼‰]*ï¼‰", "", st1)  # ä½¿ç”¨rå‰ç¼€è¡¨ç¤ºåŸå§‹å­—ç¬¦ä¸²ï¼Œé¿å…è½¬ä¹‰å­—ç¬¦çš„é—®é¢˜
            data1["text"] = st8

            try:

                logger.info(f"è°ƒç”¨{voicegg}è¯­éŸ³åˆæˆ")
                path = await superVG(data1, voicegg, voiceLangType)
                await bot.send(event, Voice(path=path))
                if withText == True:
                    await bot.send(event, st1, True)
            except Exception as e:
                logger.error(e)

                await bot.send(event, st1, True)
        else:
            if len(st1) > 400:
                await bot.send(event, st1[:100], True)
                await bot.send(event, "ğŸ±â€ğŸ’»å›å¤å¯èƒ½å­˜åœ¨å¼‚å¸¸ï¼Œ\nè¯·å‘é€ /clear ä»¥æ¸…ç†å½“å‰èŠå¤©(æ— éœ€è‰¾ç‰¹)", True)
                try:
                    prompt.remove(prompt[-1])
                    chatGLMData[event.sender.id] = prompt
                except:
                    logger.error("chatGLMåˆ é™¤ä¸Šä¸€æ¬¡å¯¹è¯å¤±è´¥")
                return
            await bot.send(event, st1, True)
        if context == True:
            # æ›´æ–°è¯¥ç”¨æˆ·prompt
            prompt.append({"role": "assistant", "content": st1})
            # è¶…è¿‡10ï¼Œç§»é™¤ç¬¬ä¸€ä¸ªå…ƒç´ 

            if len(prompt) > maxPrompt:
                logger.error("glm promptè¶…é™ï¼Œç§»é™¤å…ƒç´ ")
                del prompt[0]
                del prompt[0]
            chatGLMData[event.sender.id] = prompt
            # å†™å…¥æ–‡ä»¶
            with open('data/chatGLMData.yaml', 'w', encoding="utf-8") as file:
                yaml.dump(chatGLMData, file, allow_unicode=True)
if __name__ == '__main__':
    with open('settings.yaml', 'r', encoding='utf-8') as f:
        result = yaml.load(f.read(), Loader=yaml.FullLoader)
    config=result.get("bot")
    qq=int(config.get('botqq'))
    key=config.get("http-api-key")
    port= int(config.get("http-api-port"))
    bot = Mirai(qq, adapter=WebSocketAdapter(
        verify_key=key, host='localhost', port=port
    ))
    botName = config.get('botName')
    master=int(config.get('master'))



    #èŠå£«logger
    logger=newLogger()
    logger.info("æ¬¢è¿ä½¿ç”¨")
    logger.info("é¡¹ç›®æºåœ°å€ï¼šhttps://github.com/avilliai/Bergml")
    logger.info("æ­¤é¡¹ç›®æ‹†åˆ†è‡ªManyanaï¼šhttps://github.com/avilliai/Manyana")
    main(bot,logger)
    try:
        bot.run()
    except Exception as e:
        logger.error(e)
        input("å‡ºé”™ï¼ŒæŒ‰ä»»æ„é”®é€€å‡º")